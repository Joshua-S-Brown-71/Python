{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CS 4391 Homework 5 Programming\n",
    "Implement the __getitem__() function in this python script\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import csv\n",
    "import os, math\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "# The dataset class\n",
    "class CrackerBox(data.Dataset):\n",
    "    def __init__(self, image_set='train', data_path='/Users/JOSH/Desktop/CS 4391                     (Vision)/HW/5/yolo/data'):\n",
    "\n",
    "        self.name = 'cracker_box_' + image_set\n",
    "        self.image_set = image_set\n",
    "        self.data_path = data_path\n",
    "        self.classes = ('__background__', 'cracker_box')\n",
    "        self.width = 640\n",
    "        self.height = 480\n",
    "        self.yolo_image_size = 448\n",
    "        self.scale_width = self.yolo_image_size / self.width\n",
    "        self.scale_height = self.yolo_image_size / self.height\n",
    "        self.yolo_grid_num = 7\n",
    "        self.yolo_grid_size = self.yolo_image_size / self.yolo_grid_num\n",
    "        # split images into training set and validation set\n",
    "        self.gt_files_train, self.gt_files_val = self.list_dataset()\n",
    "        # the pixel mean for normalization\n",
    "        self.pixel_mean = np.array([[[102.9801, 115.9465, 122.7717]]], dtype=np.float32)\n",
    "\n",
    "        # training set\n",
    "        if image_set == 'train':\n",
    "            self.size = len(self.gt_files_train)\n",
    "            self.gt_paths = self.gt_files_train\n",
    "            print('%d images for training' % self.size)\n",
    "        else:\n",
    "            # validation set\n",
    "            self.size = len(self.gt_files_val)\n",
    "            self.gt_paths = self.gt_files_val\n",
    "            print('%d images for validation' % self.size)\n",
    "\n",
    "\n",
    "    # list the ground truth annotation files\n",
    "    # use the first 100 images for training\n",
    "    def list_dataset(self):\n",
    "    \n",
    "        filename = os.path.join(self.data_path, '*.txt')\n",
    "        gt_files = sorted(glob.glob(filename))\n",
    "        \n",
    "        gt_files_train = gt_files[:100]\n",
    "        gt_files_val = gt_files[100:]\n",
    "        \n",
    "        return gt_files_train, gt_files_val\n",
    "\n",
    "\n",
    "    # TODO: implement this function\n",
    "    def __getitem__(self, idx):\n",
    "        # gt file\n",
    "        filename_gt = self.gt_paths[idx]\n",
    "\n",
    "        # Load image\n",
    "        filename_image = os.path.splitext(filename_gt)[0].replace(\"-box\", \"\") + '.jpg'\n",
    "        image = cv2.imread(filename_image)\n",
    "\n",
    "        # Check if the image is loaded successfully\n",
    "        if image is None:\n",
    "            print(f\"Error: Unable to read image - {filename_image}\")\n",
    "            return {'image': torch.zeros((3, self.yolo_image_size, self.yolo_image_size)),\n",
    "                    'gt_box': torch.zeros((5, self.yolo_grid_num, self.yolo_grid_num)),\n",
    "                    'gt_mask': torch.zeros((self.yolo_grid_num, self.yolo_grid_num))}\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "        # Resize and normalize image\n",
    "        image = cv2.resize(image, (self.yolo_image_size, self.yolo_image_size))\n",
    "        image = image.astype(np.float32) - self.pixel_mean\n",
    "        image /= 255.0\n",
    "        image = image.transpose((2, 0, 1))  # (channel, height, width)\n",
    "        # Load ground truth bounding boxes\n",
    "        with open(filename_gt, 'r') as f:\n",
    "            gt_boxes = []\n",
    "            for line in f:\n",
    "                x1, y1, x2, y2 = map(float, line.strip().split())\n",
    "                # Scale bounding box\n",
    "                x1 *= self.scale_width\n",
    "                y1 *= self.scale_height\n",
    "                x2 *= self.scale_width\n",
    "                y2 *= self.scale_height\n",
    "                # Normalize bounding box\n",
    "                cx = (x1 + x2) / 2 / self.yolo_image_size\n",
    "                cy = (y1 + y2) / 2 / self.yolo_image_size\n",
    "                w = (x2 - x1) / self.yolo_image_size\n",
    "                h = (y2 - y1) / self.yolo_image_size\n",
    "                gt_boxes.append([cx, cy, w, h, 1.0])  # Confidence is 1 for ground truth\n",
    "\n",
    "        # Create gt_box tensor\n",
    "        gt_box_blob = torch.zeros((5, self.yolo_grid_num, self.yolo_grid_num))\n",
    "        for gt_box in gt_boxes:\n",
    "            cx, cy, _, _, _ = gt_box\n",
    "            grid_x = int(cx * self.yolo_grid_num)\n",
    "            grid_y = int(cy * self.yolo_grid_num)\n",
    "            gt_box_blob[:, grid_y, grid_x] = torch.tensor(gt_box)\n",
    "\n",
    "        # Create gt_mask tensor\n",
    "        gt_mask_blob = torch.zeros((self.yolo_grid_num, self.yolo_grid_num))\n",
    "        for gt_box in gt_boxes:\n",
    "            cx, cy, _, _, _ = gt_box\n",
    "            grid_x = int(cx * self.yolo_grid_num)\n",
    "            grid_y = int(cy * self.yolo_grid_num)\n",
    "            gt_mask_blob[grid_y, grid_x] = 1.0\n",
    "\n",
    "        # This is the sample dictionary to be returned from this function\n",
    "        sample = {'image': torch.tensor(image),\n",
    "                  'gt_box': gt_box_blob,\n",
    "                  'gt_mask': gt_mask_blob}\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    # len of the dataset\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "        \n",
    "\n",
    "# draw grid on images for visualization\n",
    "def draw_grid(image, line_space=64):\n",
    "    H, W = image.shape[:2]\n",
    "    image[0:H:line_space] = [255, 255, 0]\n",
    "    image[:, 0:W:line_space] = [255, 255, 0]\n",
    "\n",
    "\n",
    "# the main function for testing\n",
    "if __name__ == '__main__':\n",
    "    dataset_train = CrackerBox('train')\n",
    "    dataset_val = CrackerBox('val')\n",
    "    \n",
    "    # dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # visualize the training data\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        \n",
    "        image = sample['image'][0].numpy().transpose((1, 2, 0))\n",
    "        gt_box = sample['gt_box'][0].numpy()\n",
    "        gt_mask = sample['gt_mask'][0].numpy()\n",
    "\n",
    "        y, x = np.where(gt_mask == 1)\n",
    "        cx = gt_box[0, y, x] * dataset_train.yolo_grid_size + x * dataset_train.yolo_grid_size\n",
    "        cy = gt_box[1, y, x] * dataset_train.yolo_grid_size + y * dataset_train.yolo_grid_size\n",
    "        w = gt_box[2, y, x] * dataset_train.yolo_image_size\n",
    "        h = gt_box[3, y, x] * dataset_train.yolo_image_size\n",
    "\n",
    "        x1 = cx - w * 0.5\n",
    "        x2 = cx + w * 0.5\n",
    "        y1 = cy - h * 0.5\n",
    "        y2 = cy + h * 0.5\n",
    "\n",
    "        print(\"\\n\",image.shape, gt_box.shape)\n",
    "        \n",
    "        # visualization\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 3, 1)\n",
    "        im = image * 255.0 + dataset_train.pixel_mean\n",
    "        im = im.astype(np.uint8)\n",
    "        plt.imshow(im[:, :, (2, 1, 0)])\n",
    "        plt.title('input image (448x448)', fontsize = 5.5)\n",
    "\n",
    "        ax = fig.add_subplot(1, 3, 2)\n",
    "        draw_grid(im)\n",
    "        plt.imshow(im[:, :, (2, 1, 0)])\n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='g', facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "        plt.plot(cx, cy, 'ro', markersize=12)\n",
    "        plt.title('Ground truth bounding box in YOLO format', fontsize=5.5)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 3, 3)\n",
    "        plt.imshow(gt_mask)\n",
    "        plt.title('Ground truth mask in YOLO format (7x7)', fontsize=5.5)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CS 4391 Homework 5 Programming\n",
    "Implement the create_modules() function in this python script\n",
    "\"\"\"\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# the YOLO network class\n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, num_boxes, num_classes):\n",
    "        super(YOLO, self).__init__()\n",
    "        # number of bounding boxes per cell (2 in our case)\n",
    "        self.num_boxes = num_boxes\n",
    "        # number of classes for detection (1 in our case: cracker box)\n",
    "        self.num_classes = num_classes\n",
    "        self.image_size = 448\n",
    "        self.grid_size = 64\n",
    "        # create the network\n",
    "        self.network = self.create_modules()\n",
    "        \n",
    "        # initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    #TODO: implement this function to build the network\n",
    "    def create_modules(self):\n",
    "        modules = nn.Sequential()\n",
    "\n",
    "        ### ADD YOUR CODE HERE ###\n",
    "        # hint: use the modules.add_module()\n",
    "          # Initial convolution layers\n",
    "        modules.add_module('conv1', nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu1', nn.ReLU())\n",
    "        modules.add_module('maxpool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.add_module('conv2', nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu2', nn.ReLU())\n",
    "        modules.add_module('maxpool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.add_module('conv3', nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu3', nn.ReLU())\n",
    "        modules.add_module('maxpool3', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.add_module('conv4', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu4', nn.ReLU())\n",
    "        modules.add_module('maxpool4', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.add_module('conv5', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu5', nn.ReLU())\n",
    "        modules.add_module('maxpool5', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.add_module('conv6', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu6', nn.ReLU())\n",
    "        modules.add_module('maxpool6', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        modules.add_module('conv7', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu7', nn.ReLU())\n",
    "\n",
    "        modules.add_module('conv8', nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu8', nn.ReLU())\n",
    "\n",
    "        modules.add_module('conv9', nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1))\n",
    "        modules.add_module('relu9', nn.ReLU())\n",
    "\n",
    "        # Flatten\n",
    "        modules.add_module('flatten', nn.Flatten())\n",
    "\n",
    "        # Fully connected layers\n",
    "        modules.add_module('fc1', nn.Linear(50176, 256))\n",
    "        modules.add_module('fc2', nn.Linear(256, 256))\n",
    "        modules.add_module('fc_output', nn.Linear(256, 7 * 7 * (5 * self.num_boxes + self.num_classes)))\n",
    "        modules.add_module('sigmoid', nn.Sigmoid())\n",
    "        return modules\n",
    "\n",
    "\n",
    "    # output (batch_size, 5*B + C, 7, 7)\n",
    "    # In the network output (cx, cy, w, h) are normalized to be [0, 1]\n",
    "    # This function undo the noramlization to obtain the bounding boxes in the orignial image space\n",
    "    def transform_predictions(self, output):\n",
    "        batch_size = output.shape[0]\n",
    "        x = torch.linspace(0, 384, steps=7)\n",
    "        y = torch.linspace(0, 384, steps=7)\n",
    "        corner_x, corner_y = torch.meshgrid(x, y, indexing='xy')\n",
    "        corner_x = torch.unsqueeze(corner_x, dim=0)\n",
    "        corner_y = torch.unsqueeze(corner_y, dim=0)\n",
    "        corners = torch.cat((corner_x, corner_y), dim=0)\n",
    "        # corners are top-left corners for each cell in the grid\n",
    "        corners = corners.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "        pred_box = output.clone()\n",
    "\n",
    "        # for each bounding box\n",
    "        for i in range(self.num_boxes):\n",
    "            # x and y\n",
    "            pred_box[:, i*5, :, :] = corners[:, 0, :, :] + output[:, i*5, :, :] * self.grid_size\n",
    "            pred_box[:, i*5+1, :, :] = corners[:, 1, :, :] + output[:, i*5+1, :, :] * self.grid_size\n",
    "            # w and h\n",
    "            pred_box[:, i*5+2, :, :] = output[:, i*5+2, :, :] * self.image_size\n",
    "            pred_box[:, i*5+3, :, :] = output[:, i*5+3, :, :] * self.image_size\n",
    "\n",
    "        return pred_box\n",
    "\n",
    "\n",
    "    # forward pass of the YOLO network\n",
    "    def forward(self, x):\n",
    "        # raw output from the network\n",
    "        output = self.network(x).reshape((-1, self.num_boxes * 5 + self.num_classes, 7, 7))\n",
    "        # compute bounding boxes in the original image space\n",
    "        pred_box = self.transform_predictions(output)\n",
    "        return output, pred_box\n",
    "\n",
    "\n",
    "# run this main function for testing\n",
    "if __name__ == '__main__':\n",
    "    network = YOLO(num_boxes=2, num_classes=1)\n",
    "    print(network)\n",
    "\n",
    "    image = np.random.uniform(-0.5, 0.5, size=(1, 3, 448, 448)).astype(np.float32)\n",
    "    image_tensor = torch.from_numpy(image)\n",
    "    print('input image:', image_tensor.shape)\n",
    "\n",
    "    output, pred_box = network(image_tensor)\n",
    "    print('network output:', output.shape, pred_box.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd767a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
