{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38384892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 20:24:13.186240: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be saved to `checkpoints`\n",
      "epoch 0/1, iter 0/13, lr 0.000010, loss 9248374.0000\n",
      "epoch 0/1, iter 1/13, lr 0.000010, loss 7365337.0000\n",
      "epoch 0/1, iter 2/13, lr 0.000010, loss 6727649.5000\n",
      "epoch 0/1, iter 3/13, lr 0.000010, loss 7606620.0000\n",
      "epoch 0/1, iter 4/13, lr 0.000010, loss 9531723.0000\n",
      "epoch 0/1, iter 5/13, lr 0.000010, loss 7956521.0000\n",
      "epoch 0/1, iter 6/13, lr 0.000010, loss 7454395.5000\n",
      "epoch 0/1, iter 7/13, lr 0.000010, loss 7077055.0000\n",
      "epoch 0/1, iter 8/13, lr 0.000010, loss 7984362.5000\n",
      "epoch 0/1, iter 9/13, lr 0.000010, loss 7978441.0000\n",
      "epoch 0/1, iter 10/13, lr 0.000010, loss 7927034.5000\n",
      "epoch 0/1, iter 11/13, lr 0.000010, loss 8323111.5000\n",
      "epoch 0/1, iter 12/13, lr 0.000010, loss 4631526.5000\n",
      "yolo_final.checkpoint.pth\n",
      "save training loss plot to train_loss.pdf\n",
      "100 images for validation\n",
      "image 1/100, 98 objects detected\n",
      "image 2/100, 98 objects detected\n",
      "image 3/100, 98 objects detected\n",
      "image 4/100, 98 objects detected\n",
      "image 5/100, 98 objects detected\n",
      "image 6/100, 98 objects detected\n",
      "image 7/100, 98 objects detected\n",
      "image 8/100, 98 objects detected\n",
      "image 9/100, 98 objects detected\n",
      "image 10/100, 98 objects detected\n",
      "image 11/100, 98 objects detected\n",
      "image 12/100, 98 objects detected\n",
      "image 13/100, 98 objects detected\n",
      "image 14/100, 98 objects detected\n",
      "image 15/100, 98 objects detected\n",
      "image 16/100, 98 objects detected\n",
      "image 17/100, 98 objects detected\n",
      "image 18/100, 98 objects detected\n",
      "image 19/100, 98 objects detected\n",
      "image 20/100, 98 objects detected\n",
      "image 21/100, 98 objects detected\n",
      "image 22/100, 98 objects detected\n",
      "image 23/100, 98 objects detected\n",
      "image 24/100, 98 objects detected\n",
      "image 25/100, 98 objects detected\n",
      "image 26/100, 98 objects detected\n",
      "image 27/100, 98 objects detected\n",
      "image 28/100, 98 objects detected\n",
      "image 29/100, 98 objects detected\n",
      "image 30/100, 98 objects detected\n",
      "image 31/100, 98 objects detected\n",
      "image 32/100, 98 objects detected\n",
      "image 33/100, 98 objects detected\n",
      "image 34/100, 98 objects detected\n",
      "image 35/100, 98 objects detected\n",
      "image 36/100, 98 objects detected\n",
      "image 37/100, 98 objects detected\n",
      "image 38/100, 98 objects detected\n",
      "image 39/100, 98 objects detected\n",
      "image 40/100, 98 objects detected\n",
      "image 41/100, 98 objects detected\n",
      "image 42/100, 98 objects detected\n",
      "image 43/100, 98 objects detected\n",
      "image 44/100, 98 objects detected\n",
      "image 45/100, 98 objects detected\n",
      "image 46/100, 98 objects detected\n",
      "image 47/100, 98 objects detected\n",
      "image 48/100, 98 objects detected\n",
      "image 49/100, 98 objects detected\n",
      "image 50/100, 98 objects detected\n",
      "image 51/100, 98 objects detected\n",
      "image 52/100, 98 objects detected\n",
      "image 53/100, 98 objects detected\n",
      "image 54/100, 98 objects detected\n",
      "image 55/100, 98 objects detected\n",
      "image 56/100, 98 objects detected\n",
      "image 57/100, 98 objects detected\n",
      "image 58/100, 98 objects detected\n",
      "image 59/100, 98 objects detected\n",
      "image 60/100, 98 objects detected\n",
      "image 61/100, 98 objects detected\n",
      "image 62/100, 98 objects detected\n",
      "image 63/100, 98 objects detected\n",
      "image 64/100, 98 objects detected\n",
      "image 65/100, 98 objects detected\n",
      "image 66/100, 98 objects detected\n",
      "image 67/100, 98 objects detected\n",
      "image 68/100, 98 objects detected\n",
      "image 69/100, 98 objects detected\n",
      "image 70/100, 98 objects detected\n",
      "image 71/100, 98 objects detected\n",
      "image 72/100, 98 objects detected\n",
      "image 73/100, 98 objects detected\n",
      "image 74/100, 98 objects detected\n",
      "image 75/100, 98 objects detected\n",
      "image 76/100, 98 objects detected\n",
      "image 77/100, 98 objects detected\n",
      "image 78/100, 98 objects detected\n",
      "image 79/100, 98 objects detected\n",
      "image 80/100, 98 objects detected\n",
      "image 81/100, 98 objects detected\n",
      "image 82/100, 98 objects detected\n",
      "image 83/100, 98 objects detected\n",
      "image 84/100, 98 objects detected\n",
      "image 85/100, 98 objects detected\n",
      "image 86/100, 98 objects detected\n",
      "image 87/100, 98 objects detected\n",
      "image 88/100, 98 objects detected\n",
      "image 89/100, 98 objects detected\n",
      "image 90/100, 98 objects detected\n",
      "image 91/100, 98 objects detected\n",
      "image 92/100, 98 objects detected\n",
      "image 93/100, 98 objects detected\n",
      "image 94/100, 98 objects detected\n",
      "image 95/100, 98 objects detected\n",
      "image 96/100, 98 objects detected\n",
      "image 97/100, 98 objects detected\n",
      "image 98/100, 98 objects detected\n",
      "image 99/100, 98 objects detected\n",
      "image 100/100, 98 objects detected\n",
      "Detection AP 0.002641991964382888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CS 4391 Homework 5 Programming\n",
    "Run this script for YOLO training\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import os, math\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from HW5T import CrackerBox\n",
    "from HW5T import YOLO\n",
    "from HW5T import compute_loss\n",
    "\n",
    "\n",
    "# plot losses\n",
    "def plot_losses(losses, filename='train_loss.pdf'):\n",
    "\n",
    "    num_epoches = losses.shape[0]\n",
    "    l = np.mean(losses, axis=1)\n",
    "\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(range(num_epoches), l, marker='o', alpha=0.5, ms=4)\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    loss_xlim = plt.xlim()\n",
    "\n",
    "    plt.gcf().set_size_inches(6, 4)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    print('save training loss plot to %s' % (filename))\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # hyper-parameters\n",
    "    # you can tune these for your training\n",
    "    num_epochs = 1\n",
    "    batch_size = 8\n",
    "    learning_rate = 1e-5\n",
    "    num_workers = 1\n",
    "    \n",
    "    # dataset\n",
    "    dataset_train = CrackerBox('train')  \n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    epoch_size = len(train_loader)\n",
    "\n",
    "    # network\n",
    "    num_classes = 1\n",
    "    num_boxes = 2\n",
    "    network = YOLO(num_boxes, num_classes)\n",
    "    image_size = network.image_size\n",
    "    grid_size = network.grid_size\n",
    "    network.train()\n",
    "\n",
    "    # Optimizer: Adam\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # create output directory\n",
    "    output_dir = 'checkpoints'\n",
    "    print('Output will be saved to `{:s}`'.format(output_dir))\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # save the losses\n",
    "    losses = np.zeros((num_epochs, epoch_size), dtype=np.float32)\n",
    "    # for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # for each sample\n",
    "        for i, sample in enumerate(train_loader):\n",
    "            image = sample['image'].float()  # Ensure correct data type\n",
    "            gt_box = sample['gt_box']\n",
    "            gt_mask = sample['gt_mask']\n",
    "\n",
    "            # forward pass\n",
    "            output, pred_box = network(image)\n",
    "\n",
    "            # compute loss\n",
    "            loss = compute_loss(output, pred_box, gt_box, gt_mask, num_boxes, num_classes, grid_size, image_size)\n",
    "\n",
    "            # optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print('epoch %d/%d, iter %d/%d, lr %.6f, loss %.4f' % (epoch, num_epochs, i, epoch_size, learning_rate, loss))\n",
    "            losses[epoch, i] = loss\n",
    "\n",
    "        '''\n",
    "        # save checkpoint for every epoch\n",
    "        state = network.state_dict()\n",
    "        filename = 'yolo_epoch_{:d}'.format(epoch+1) + '.checkpoint.pth'\n",
    "        torch.save(state, os.path.join(output_dir, filename))\n",
    "        print(filename)\n",
    "        '''\n",
    "        \n",
    "    # save the final checkpoint\n",
    "    state = network.state_dict()\n",
    "    filename = 'yolo_final.checkpoint.pth'\n",
    "    torch.save(state, os.path.join(output_dir, filename))\n",
    "    print(filename)\n",
    "\n",
    "    # plot loss\n",
    "    plot_losses(losses)\n",
    "\"\"\"\n",
    "CS 4391 Homework 5 Programming\n",
    "Run this script for YOLO testing\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import os, math\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from HW5T import CrackerBox\n",
    "from HW5T import YOLO\n",
    "from voc_eval import voc_eval\n",
    "\n",
    "\n",
    "# from the network prediction, extract the bounding boxes with confidences larger than threshold\n",
    "# pred_box: (batch_size, num_boxes * 5 + num_classes, 7, 7), predicted bounding boxes from the network (see the forward() function)\n",
    "def extract_detections(pred_box, threshold, num_boxes):\n",
    "\n",
    "    # extract boxes\n",
    "    boxes_all = np.zeros((0, 5), dtype=np.float32)\n",
    "    for i in range(num_boxes):\n",
    "        confidence = pred_box[0, 5*i+4].detach().numpy()\n",
    "        y, x = np.where(confidence > threshold)\n",
    "        boxes = pred_box[0, 5*i:5*i+5, y, x].detach().numpy().transpose()        \n",
    "        boxes_all = np.concatenate((boxes_all, boxes), axis=0)\n",
    "\n",
    "    # convert to (x1, y1, x2, y2)\n",
    "    boxes = boxes_all.copy()\n",
    "    boxes[:, 0] = boxes_all[:, 0] - boxes_all[:, 2] * 0.5\n",
    "    boxes[:, 2] = boxes_all[:, 0] + boxes_all[:, 2] * 0.5\n",
    "    boxes[:, 1] = boxes_all[:, 1] - boxes_all[:, 3] * 0.5\n",
    "    boxes[:, 3] = boxes_all[:, 1] + boxes_all[:, 3] * 0.5\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# visualize the detections\n",
    "def visualize(image, gt, detections):\n",
    "    \n",
    "    im = image[0].permute(1, 2, 0).numpy()\n",
    "    pixel_mean = np.array([[[102.9801, 115.9465, 122.7717]]], dtype=np.float32)\n",
    "\n",
    "    # show ground truth\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    im = im * 255.0 + pixel_mean\n",
    "    im = im.astype(np.uint8)\n",
    "    plt.imshow(im[:, :, (2, 1, 0)])\n",
    "    rect = patches.Rectangle((gt[0, 0], gt[0, 1]), gt[0, 2]-gt[0, 0], gt[0, 3]-gt[0, 1], linewidth=2, edgecolor='g', facecolor=\"none\")\n",
    "    ax.add_patch(rect) \n",
    "    plt.title('ground truth')   \n",
    "    \n",
    "    # show detection\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(im[:, :, (2, 1, 0)])\n",
    "    plt.title('prediction')\n",
    "    for i in range(detections.shape[0]):   \n",
    "        x1 = detections[i, 0]\n",
    "        x2 = detections[i, 2]\n",
    "        y1 = detections[i, 1]\n",
    "        y2 = detections[i, 3]\n",
    "        score = detections[i, 4]\n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='g', facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "        plt.plot((x1+x2)/2, (y1+y2)/2, 'ro')\n",
    "        ax.text(x1, y1, '%.2f' % score, color = 'y')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# main function for testing\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # dataset\n",
    "    dataset = CrackerBox('val')  \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "    epoch_size = len(data_loader)\n",
    "\n",
    "    # network\n",
    "    num_classes = 1\n",
    "    num_boxes = 2\n",
    "    network = YOLO(num_boxes, num_classes)\n",
    "    image_size = network.image_size\n",
    "    grid_size = network.grid_size\n",
    "\n",
    "    # load checkpoint\n",
    "    output_dir = 'checkpoints'\n",
    "    filename = 'yolo_final.checkpoint.pth'\n",
    "    filename = os.path.join(output_dir, filename)\n",
    "    network.load_state_dict(torch.load(filename))\n",
    "    network.eval()\n",
    "    \n",
    "    # detection threshold\n",
    "    threshold = 0.1\n",
    "\n",
    "    # main test loop\n",
    "    results_gt = []\n",
    "    results_pred = []\n",
    "    for i, sample in enumerate(data_loader):\n",
    "        \n",
    "        image = sample['image']\n",
    "        gt_box = sample['gt_box']\n",
    "        gt_mask = sample['gt_mask']\n",
    "\n",
    "        # forward pass\n",
    "        output, pred_box = network(image)\n",
    "        \n",
    "        # convert gt box\n",
    "        gt_box = sample['gt_box'][0].numpy()\n",
    "        gt_mask = sample['gt_mask'][0].numpy()\n",
    "        y, x = np.where(gt_mask == 1)\n",
    "        cx = gt_box[0, y, x] * dataset.yolo_grid_size + x * dataset.yolo_grid_size\n",
    "        cy = gt_box[1, y, x] * dataset.yolo_grid_size + y * dataset.yolo_grid_size\n",
    "        w = gt_box[2, y, x] * dataset.yolo_image_size\n",
    "        h = gt_box[3, y, x] * dataset.yolo_image_size\n",
    "        x1 = cx - w * 0.5\n",
    "        x2 = cx + w * 0.5\n",
    "        y1 = cy - h * 0.5\n",
    "        y2 = cy + h * 0.5        \n",
    "        gt = np.array([x1, y1, x2, y2]).reshape((1, 4))\n",
    "        results_gt.append(gt)\n",
    "        \n",
    "        # extract predictions\n",
    "        detections = extract_detections(pred_box, threshold, num_boxes)\n",
    "        results_pred.append(detections)\n",
    "        print('image %d/%d, %d objects detected' % (i+1, epoch_size, detections.shape[0]))\n",
    "\n",
    "        # visualization, uncomment the follow line to see the detection results\n",
    "        # visualize(image, gt, detections)\n",
    "        \n",
    "    # evaluation\n",
    "    rec, prec, ap = voc_eval(results_gt, results_pred)\n",
    "    print('Detection AP', ap)\n",
    "    \n",
    "    # save the PR curve\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    plt.plot(rec, prec)\n",
    "    plt.xlabel('recall')\n",
    "    plt.ylabel('precision')\n",
    "    plt.title('AP: %.2f' % ap)\n",
    "    plt.gcf().set_size_inches(6, 4)\n",
    "    plt.savefig('test_ap.pdf', bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9f4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69bb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
