{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35689961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structural Similarity Index (SSIM): 1.0000 \n",
      "(Range: [0, 1]) [Optimal: 1]\n",
      "\n",
      "Mean Squared Error (MSE): 0.0000 \n",
      "(Range: [0, ∞)) [Optimal: 0]\n",
      "\n",
      "Cross-Correlation: 1.0000 \n",
      "(Range: [-1, 1]) [Optimal: 1]\n",
      "\n",
      "Perceptual Hashing Similarity: 1.0000 \n",
      "(Range: [0, 1]) [Optimal: 1]\n",
      "\n",
      "Histogram Similarity: 1.0000 \n",
      "(Range: [-1, 1]) [Optimal: 1]\n",
      "\n",
      "Overall Similarity Score: 100.00 out of 100\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "def bilateral_filtering(\n",
    "        img: np.uint8,\n",
    "        spatial_variance: float,\n",
    "        intensity_variance: float,\n",
    "        kernel_size: int,\n",
    ") -> np.uint8:\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not loaded.\")\n",
    "\n",
    "    img = img / 255.0  # Normalize to [0, 1] range\n",
    "    img_filtered = np.zeros_like(img)  # Placeholder of the filtered image\n",
    "\n",
    "    sizeX, sizeY, channels = img.shape\n",
    "\n",
    "    kernel_half_size = kernel_size // 2\n",
    "\n",
    "    for i in range(sizeX):\n",
    "        for j in range(sizeY):\n",
    "            for c in range(channels):\n",
    "                filtered_pixel_value = 0.0\n",
    "                normalization_factor = 0.0\n",
    "                for k in range(-kernel_half_size, kernel_half_size + 1):\n",
    "                    for l in range(-kernel_half_size, kernel_half_size + 1):\n",
    "                        x = i + k\n",
    "                        y = j + l\n",
    "                        if 0 <= x < sizeX and 0 <= y < sizeY:\n",
    "                            spatial_weight = np.exp(-(k ** 2 + l ** 2) / (2 * spatial_variance ** 2))\n",
    "                            intensity_weight = np.exp(-(img[i, j, c] - img[x, y, c]) ** 2 / (2 * intensity_variance ** 2))\n",
    "                            bilateral_weight = spatial_weight * intensity_weight\n",
    "                            filtered_pixel_value += img[x, y, c] * bilateral_weight\n",
    "                            normalization_factor += bilateral_weight\n",
    "                img_filtered[i, j, c] = filtered_pixel_value / normalization_factor\n",
    "\n",
    "    img_filtered = (img_filtered * 255).astype(np.uint8)\n",
    "    return img_filtered\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    ssim_index, _ = ssim(img1, img2, full=True, channel_axis=-1)\n",
    "    return ssim_index\n",
    "\n",
    "def calculate_mse(img1, img2):\n",
    "    mse = np.sum((img1 - img2) ** 2) / float(img1.size)\n",
    "    return mse\n",
    "\n",
    "def calculate_cross_correlation(img1, img2):\n",
    "    cross_correlation = cv2.matchTemplate(img1, img2, cv2.TM_CCOEFF_NORMED)[0, 0]\n",
    "    return cross_correlation\n",
    "\n",
    "def calculate_perceptual_hash_similarity(img1, img2):\n",
    "    hash1 = imagehash.dhash(Image.fromarray(img1))\n",
    "    hash2 = imagehash.dhash(Image.fromarray(img2))\n",
    "    hash_similarity = 1 - (hash1 - hash2) / len(hash1.hash) ** 2\n",
    "    return hash_similarity\n",
    "\n",
    "def calculate_histogram_similarity(img1, img2):\n",
    "    hist1 = cv2.calcHist([img1], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "    hist2 = cv2.calcHist([img2], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return similarity\n",
    "\n",
    "def calculate_overall_similarity_score(ssim_index, mse, cross_correlation, hash_similarity, hist_similarity):\n",
    "    # Normalize each metric to the range [0, 1]\n",
    "    ssim_normalized = ssim_index\n",
    "    mse_normalized = 1.0 - (mse / (mse + 1.0))  # Normalize MSE to [0, 1], minimizing the effect of large MSE\n",
    "    cross_correlation_normalized = (cross_correlation + 1.0) / 2.0  # Normalize Cross-Correlation to [0, 1]\n",
    "    hash_similarity_normalized = (hash_similarity + 1.0) / 2.0  # Normalize Hash Similarity to [0, 1]\n",
    "    hist_similarity_normalized = (hist_similarity + 1.0) / 2.0  # Normalize Histogram Similarity to [0, 1]\n",
    "\n",
    "    # Assign equal weight to each metric\n",
    "    weight_ssim = 1.0\n",
    "    weight_mse = 1.0\n",
    "    weight_cross_correlation = 1.0\n",
    "    weight_hash_similarity = 1.0\n",
    "    weight_hist_similarity = 1.0\n",
    "\n",
    "    # Calculate the overall similarity score\n",
    "    overall_similarity_score = (\n",
    "        weight_ssim * ssim_normalized +\n",
    "        weight_mse * mse_normalized +\n",
    "        weight_cross_correlation * cross_correlation_normalized +\n",
    "        weight_hash_similarity * hash_similarity_normalized +\n",
    "        weight_hist_similarity * hist_similarity_normalized\n",
    "    ) / (weight_ssim + weight_mse + weight_cross_correlation + weight_hash_similarity + weight_hist_similarity)\n",
    "\n",
    "    # Convert to a percentage\n",
    "    overall_similarity_score_percent = overall_similarity_score * 100.0\n",
    "\n",
    "    return overall_similarity_score_percent\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage\n",
    "    image_path1 = '/Users/JOSH/Desktop/CS 4391                     (Vision)/Project/pics/1700/6.jpg'\n",
    "    image_path2 = '/Users/JOSH/Desktop/CS 4391                     (Vision)/Project/pics/1700/6.jpg'\n",
    "\n",
    "    # Load the images\n",
    "    img1 = cv2.imread(image_path1)\n",
    "    img2 = cv2.imread(image_path2)\n",
    "\n",
    "    if img1 is None:\n",
    "        raise ValueError(\"Image 1 not loaded.\")\n",
    "    if img2 is None:\n",
    "        raise ValueError(\"Image 2 not loaded.\")\n",
    "\n",
    "    # Resize images to a common size\n",
    "    common_height, common_width = 256, 256  # Adjust dimensions as needed\n",
    "    img1 = cv2.resize(img1, (common_width, common_height))\n",
    "    img2 = cv2.resize(img2, (common_width, common_height))\n",
    "\n",
    "    # Apply bilateral filtering\n",
    "    spatial_variance = 50\n",
    "    intensity_variance = 50\n",
    "    kernel_size = 5\n",
    "\n",
    "    try:\n",
    "        filtered_img1 = bilateral_filtering(img1, spatial_variance, intensity_variance, kernel_size)\n",
    "        filtered_img2 = bilateral_filtering(img2, spatial_variance, intensity_variance, kernel_size)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during bilateral filtering: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim_index = calculate_ssim(filtered_img1, filtered_img2)\n",
    "    print(f\"Structural Similarity Index (SSIM): {ssim_index:.4f} \\n(Range: [0, 1]) [Optimal: 1]\\n\")\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = calculate_mse(filtered_img1, filtered_img2)\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f} \\n(Range: [0, ∞)) [Optimal: 0]\\n\")\n",
    "\n",
    "    # Calculate Cross-Correlation\n",
    "    cross_correlation = calculate_cross_correlation(filtered_img1, filtered_img2)\n",
    "    print(f\"Cross-Correlation: {cross_correlation:.4f} \\n(Range: [-1, 1]) [Optimal: 1]\\n\")\n",
    "\n",
    "    # Calculate Perceptual Hashing Similarity\n",
    "    hash_similarity = calculate_perceptual_hash_similarity(filtered_img1, filtered_img2)\n",
    "    print(f\"Perceptual Hashing Similarity: {hash_similarity:.4f} \\n(Range: [0, 1]) [Optimal: 1]\\n\")\n",
    "\n",
    "    # Calculate Histogram Similarity\n",
    "    hist_similarity = calculate_histogram_similarity(filtered_img1, filtered_img2)\n",
    "    print(f\"Histogram Similarity: {hist_similarity:.4f} \\n(Range: [-1, 1]) [Optimal: 1]\\n\")\n",
    "\n",
    "    overall_similarity_score = calculate_overall_similarity_score(ssim_index, mse, cross_correlation, hash_similarity, hist_similarity)\n",
    "    print(f\"Overall Similarity Score: {overall_similarity_score:.2f} out of 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee51e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
